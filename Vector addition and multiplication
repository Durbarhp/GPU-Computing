{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJaz9oYCuriA",
        "outputId": "4ca6ba7a-0af8-46f2-e8d2-7b96429d40a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.10/dist-packages (2024.1)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.10/dist-packages (from pycuda) (2023.1.1)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "from pycuda.compiler import SourceModule"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1:\n",
        "\n",
        "a) Implement a kernel which takes two vectors A and B and adds them together to form a vector C.\n",
        "\n"
      ],
      "metadata": {
        "id": "0uX44a96CWLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the CUDA kernel"
      ],
      "metadata": {
        "id": "6qxKAMLUDQvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "modd = SourceModule(\"\"\"\n",
        "__global__ void times_two(const double* A, double* B)\n",
        "      {\n",
        "      uint index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "      B[index] = A[index] * 2;\n",
        "      }\n",
        "  \"\"\")\n"
      ],
      "metadata": {
        "id": "DQ1b1t9XDYqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "9IHPsFtyFixb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make an example"
      ],
      "metadata": {
        "id": "N0f7L9hWMEzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the input vectors.\n",
        "\n",
        "A = np.random.randn(10)\n",
        "A = A.astype(float)\n",
        "\n",
        "# Allocate the memory on the GPU and copy the vectors.\n",
        "\n",
        "A_gpu = cuda.mem_alloc(A.size * A.dtype.itemsize)\n",
        "cuda.memcpy_htod(A_gpu, A)\n",
        "\n",
        "B = np.empty_like(A)\n",
        "B_gpu = cuda.mem_alloc(B.size * B.dtype.itemsize)\n",
        "\n",
        "# Call the CUDA kernel.\n",
        "\n",
        "vector_addition = modd.get_function(\"times_two\")\n",
        "vector_addition(A_gpu, B_gpu, block=(10, 1, 1), grid=(1, 1, 1))\n",
        "\n",
        "\n",
        "# Copy the result back to the host.\n",
        "\n",
        "cuda.memcpy_dtoh(B, B_gpu)\n",
        "\n",
        "A_gpu.free()\n",
        "B_gpu.free()\n",
        "\n",
        "\n",
        "# Do same calculation in CPU.\n",
        "\n",
        "B_cpu = A * 2\n",
        "\n",
        "  # Verify the result\n",
        "print(B)\n",
        "print(B_cpu)\n",
        "if (B_cpu == B).all():\n",
        "  print(\"Both vectors are the same.\")\n",
        "else:\n",
        "  print(\"Vectors are not equal, something went wrong!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkD8W06rIJ_3",
        "outputId": "776cf0dd-f807-4faa-a014-899ba88cf351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3.2605579   0.9304217   0.57187967 -1.69404532  1.10728114  0.09594694\n",
            " -0.6645461   0.89700817  1.39642377  0.78339934]\n",
            "[ 3.2605579   0.9304217   0.57187967 -1.69404532  1.10728114  0.09594694\n",
            " -0.6645461   0.89700817  1.39642377  0.78339934]\n",
            "Both vectors are the same.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "globals().clear()"
      ],
      "metadata": {
        "id": "CCVGevaLMkxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2"
      ],
      "metadata": {
        "id": "40I_D90sOF8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement a kernel which multiplies two matrices together"
      ],
      "metadata": {
        "id": "ZRBbuDKDOH-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define matrix multiplication kernel"
      ],
      "metadata": {
        "id": "j246gFJxOYpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "from pycuda.compiler import SourceModule\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1eF-DruxvWN",
        "outputId": "2618d20a-05c0-4bd4-a2eb-a2ed369527cb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.10/dist-packages (2024.1)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.10/dist-packages (from pycuda) (2023.1.1)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Cuda kernel\n",
        "/N number of rows A\n",
        "      M number of columns A\n",
        "      K number of columns B"
      ],
      "metadata": {
        "id": "tTBFJxyXz9Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modd = SourceModule(\"\"\"\n",
        "__global__ void matrix_multiplication(const double* A, const double* B, double* C, int N, int M, int K)\n",
        "{\n",
        "\n",
        "    uint row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    uint col = blockIdx.x * blockDim.x + threadIdx.x; // col\n",
        "    uint mul_result = 0;\n",
        "\n",
        "    for (int k = 0; k < N; k++)\n",
        "    {\n",
        "        mul_result += A[row * N + k] * B[k * M + col];\n",
        "    }\n",
        "    C[row * M + col] = mul_result;\n",
        "}\n",
        "\"\"\")\n",
        "\n"
      ],
      "metadata": {
        "id": "2HQTaqfKONIf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "matrix multiplication kernel"
      ],
      "metadata": {
        "id": "1pQZF_PAPQ4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "rBNR3csSPVZd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation"
      ],
      "metadata": {
        "id": "N4vOLpH5RBa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize vector size\n",
        "vec_size = 10\n",
        "value_type  = float\n",
        "\n",
        "# Generate data\n",
        "N = 3\n",
        "M = 3\n",
        "K = 3\n",
        "\n",
        "\n",
        "block_number   = 32\n",
        "\n",
        "numThreadsPerBlock  = N*K*2\n",
        "\n",
        "\n",
        "a = np.random.randint(vec_size, size=(N,M))\n",
        "a = a.astype(value_type)\n",
        "\n",
        "b = np.random.randint(vec_size, size=(M,K))\n",
        "b = b.astype(value_type)\n",
        "\n",
        "# Allocate memory in GPU and copy data\n",
        "\n",
        "a_gpu = cuda.mem_alloc(a.size * a.dtype.itemsize)\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "\n",
        "b_gpu = cuda.mem_alloc(b.size * b.dtype.itemsize)\n",
        "cuda.memcpy_htod(b_gpu, b)\n",
        "\n",
        "c = np.empty([N, K])\n",
        "c_gpu = cuda.mem_alloc(b.size * b.dtype.itemsize)\n",
        "\n",
        "\n",
        "# Call  CUDA kernel.\n",
        "matrix_multiplication = modd.get_function(\"matrix_multiplication\")\n",
        "\n",
        "matrix_multiplication(a_gpu, b_gpu, c_gpu, np.int32(N), np.int32(M), np.int32(K), block=(numThreadsPerBlock, 1, 1), grid=(block_number,block_number, 1))\n",
        "# Copy the result back to the host.\n",
        "cuda.memcpy_dtoh(c, c_gpu)\n",
        "\n",
        "# Result checking\n",
        "a_gpu.free()\n",
        "b_gpu.free()\n",
        "c_gpu.free()\n",
        "\n",
        "#calculation in CPU\n",
        "\n",
        "c_cpu = np.dot(a, b)\n",
        "\n",
        "  # Verify the result\n",
        "print('a\\n',a)\n",
        "print('b\\n',b)\n",
        "print('c\\n',c)\n",
        "print('c_cpu\\n',c_cpu)\n",
        "if (c_cpu == c).all():\n",
        "  print(\"Vectors match! Same vector\")\n",
        "else:\n",
        "  print(\"Vectors are not equal. Error!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1vJ0M-wRG7G",
        "outputId": "0c8a94c0-0481-4e7d-bd9e-1a571ab1abd0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            " [[5. 0. 9.]\n",
            " [5. 8. 5.]\n",
            " [2. 1. 9.]]\n",
            "b\n",
            " [[4. 4. 3.]\n",
            " [1. 8. 9.]\n",
            " [4. 4. 7.]]\n",
            "c\n",
            " [[ 56.  56.  78.]\n",
            " [ 48. 104. 122.]\n",
            " [ 45.  52.  78.]]\n",
            "c_cpu\n",
            " [[ 56.  56.  78.]\n",
            " [ 48. 104. 122.]\n",
            " [ 45.  52.  78.]]\n",
            "Vectors match! Same vector\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "globals().clear()"
      ],
      "metadata": {
        "id": "IRx39cSMAswi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task3"
      ],
      "metadata": {
        "id": "WqZttR0gSwe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extend the kernel from task 2 to use shared memory."
      ],
      "metadata": {
        "id": "zcCtxACdSxpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "LBfEI6F_TsuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA kernel with shared memory\n",
        "modd = SourceModule(\"\"\"\n",
        "#define TILE_WIDTH 16\n",
        "\n",
        "__global__ void matrix_multiplication(const double* A, const double* B, double* C, int N, int M, int K)\n",
        "{\n",
        "    __shared__ double shared_A[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ double shared_B[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "\n",
        "    int row = by * blockDim.y + ty;\n",
        "    int col = bx * blockDim.x + tx;\n",
        "\n",
        "    double mul_result = 0;\n",
        "\n",
        "    for (int ph = 0; ph < (M - 1) / TILE_WIDTH + 1; ph++) {\n",
        "        if (row < N && ph * TILE_WIDTH + tx < M)\n",
        "            shared_A[ty][tx] = A[row * M + ph * TILE_WIDTH + tx];\n",
        "        else\n",
        "            shared_A[ty][tx] = 0.0;\n",
        "\n",
        "        if (ph * TILE_WIDTH + ty < M && col < K)\n",
        "            shared_B[ty][tx] = B[(ph * TILE_WIDTH + ty) * K + col];\n",
        "        else\n",
        "            shared_B[ty][tx] = 0.0;\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int k = 0; k < TILE_WIDTH; k++)\n",
        "            mul_result += shared_A[ty][k] * shared_B[k][tx];\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (row < N && col < K)\n",
        "        C[row * K + col] = mul_result;\n",
        "}\n",
        "\"\"\")\n",
        "\n"
      ],
      "metadata": {
        "id": "QK2bQDIqJCCB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize vector size\n",
        "vec_size = 10\n",
        "value_type = np.float64  # Change to np.float32 if needed\n",
        "\n",
        "# Generate data\n",
        "N = 3\n",
        "M = 3\n",
        "K = 3\n",
        "\n",
        "block_size = 16\n",
        "block_number = ((N - 1) // block_size + 1, (K - 1) // block_size + 1)\n",
        "\n",
        "num_threads_per_block = block_size\n",
        "\n",
        "# Create random matrices\n",
        "a = np.random.randint(vec_size, size=(N, M)).astype(value_type)\n",
        "b = np.random.randint(vec_size, size=(M, K)).astype(value_type)\n",
        "\n",
        "# Allocate memory in GPU and copy data\n",
        "a_gpu = cuda.mem_alloc(a.size * a.dtype.itemsize)\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "\n",
        "b_gpu = cuda.mem_alloc(b.size * b.dtype.itemsize)\n",
        "cuda.memcpy_htod(b_gpu, b)\n",
        "\n",
        "c_gpu = cuda.mem_alloc(b.size * b.dtype.itemsize)\n",
        "\n",
        "# Call CUDA kernel with shared memory\n",
        "matrix_multiplication_shared = modd.get_function(\"matrix_multiplication\")\n",
        "matrix_multiplication_shared(a_gpu, b_gpu, c_gpu, np.int32(N), np.int32(M), np.int32(K), block=(block_size, block_size, 1), grid=block_number)\n",
        "\n",
        "# Copy the result back to the host\n",
        "c = np.empty([N, K])\n",
        "cuda.memcpy_dtoh(c, c_gpu)\n",
        "\n",
        "# Result checking\n",
        "c_cpu = np.dot(a, b)\n",
        "\n",
        "# Verify the result\n",
        "print('a\\n', a)\n",
        "print('b\\n', b)\n",
        "print('c\\n', c)\n",
        "print('c_cpu\\n', c_cpu)\n",
        "\n",
        "if np.allclose(c_cpu, c, rtol=1e-05):\n",
        "    print(\"Matrices match! Same result.\")\n",
        "else:\n",
        "    print(\"Matrices are not equal. Error!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gfCnGIXJJEW",
        "outputId": "ec73eebc-0746-49b2-f3de-6b9fa055d401"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            " [[1. 2. 1.]\n",
            " [3. 6. 8.]\n",
            " [9. 8. 2.]]\n",
            "b\n",
            " [[3. 2. 8.]\n",
            " [3. 0. 1.]\n",
            " [2. 7. 0.]]\n",
            "c\n",
            " [[11.  9. 10.]\n",
            " [43. 62. 30.]\n",
            " [55. 32. 80.]]\n",
            "c_cpu\n",
            " [[11.  9. 10.]\n",
            " [43. 62. 30.]\n",
            " [55. 32. 80.]]\n",
            "Matrices match! Same result.\n"
          ]
        }
      ]
    }
  ]
}
